# ì„¤ì • ì˜µì…˜

> LLM Loadtest í™˜ê²½ë³€ìˆ˜ ë° ì„¤ì • ê°€ì´ë“œ

## í™˜ê²½ë³€ìˆ˜

| ë³€ìˆ˜ | ì„¤ëª… | ê¸°ë³¸ê°’ |
|------|------|--------|
| `API_KEY` | API ì¸ì¦ í‚¤ (ì„¤ì • ì‹œ ì¸ì¦ í™œì„±í™”) | (ì—†ìŒ) |
| `DATABASE_PATH` | SQLite DB ê²½ë¡œ | `/data/benchmarks.db` |
| `LOG_LEVEL` | ë¡œê·¸ ë ˆë²¨ | `INFO` |
| `PORT` | API ì„œë²„ í¬íŠ¸ | `8085` |

---

## ì¸ì¦ ì„¤ì •

```bash
# ì¸ì¦ ì—†ì´ ì‹¤í–‰ (ê¸°ë³¸)
docker compose up -d

# ì¸ì¦ í™œì„±í™”
API_KEY=your-secret-key docker compose up -d

# API í˜¸ì¶œ ì‹œ í—¤ë” ì¶”ê°€
curl -X POST http://localhost:8085/api/v1/benchmark/run \
  -H "X-API-Key: your-secret-key" \
  -H "Content-Type: application/json" \
  -d '{"server_url": "...", "model": "..."}'
```

---

## ë¡œê¹… í˜•ì‹

êµ¬ì¡°í™”ëœ JSON ë¡œê·¸ (structlog):

```json
{
  "event": "request_started",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "method": "POST",
  "path": "/api/v1/benchmark/run",
  "client_ip": "172.17.0.1",
  "timestamp": "2026-01-10T12:00:00.123456Z",
  "level": "info"
}
```

---

## Docker Compose ì„¤ì •

```yaml
# docker-compose.yml ì£¼ìš” ì„¤ì •
services:
  api:
    environment:
      - API_KEY=${API_KEY:-}
      - DATABASE_PATH=/data/benchmarks.db
      - LOG_LEVEL=INFO
    ports:
      - "8085:8085"
    volumes:
      - ./data:/data

  web:
    ports:
      - "5050:5050"
    depends_on:
      - api
```

---

## ì§€ì› ì„œë²„ (ì–´ëŒ‘í„°)

| ì„œë²„ | ì–´ëŒ‘í„° | ìƒíƒœ | ë¹„ê³  |
|------|--------|------|------|
| **vLLM** | openai | âœ… ì§€ì› | OpenAI-compatible API |
| **SGLang** | openai | âœ… ì§€ì› | OpenAI-compatible API |
| **Ollama** | openai | âœ… ì§€ì› | OpenAI-compatible API |
| **LMDeploy** | openai | âœ… ì§€ì› | OpenAI-compatible API |
| **Triton** | triton | ğŸš§ ê°œë°œ ì¤‘ | Triton HTTP API |
| **TensorRT-LLM** | trtllm | ğŸ“‹ ì˜ˆì • | - |
