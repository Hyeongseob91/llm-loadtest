# FAQ

> LLM Loadtest 자주 묻는 질문

## Q: TTFT와 E2E Latency의 차이는?

**A**:
- **TTFT**: 첫 토큰까지의 시간 (응답 시작)
- **E2E**: 전체 응답 완료까지의 시간

스트리밍 환경에서 TTFT가 빠르면 사용자는 빠른 응답을 인지하지만, 전체 응답은 더 오래 걸릴 수 있습니다.

---

## Q: Goodput이 낮은 이유는?

**A**:
1. **SLO 임계값이 너무 엄격함**: 더 여유 있는 값으로 조정
2. **동시성이 서버 용량 초과**: 동시성 레벨 감소
3. **서버 리소스 부족**: GPU 메모리, CPU 확인

---

## Q: GPU 모니터링이 안 되는 경우?

**A**:
1. **pynvml 설치 필요**: `pip install nvidia-ml-py`
2. **NVIDIA GPU만 지원**: AMD GPU는 미지원
3. **드라이버 확인**: NVIDIA 드라이버가 설치되어 있어야 함

---

## Q: 토큰 카운팅이 부정확한 경우?

**A**:
1. **tiktoken 미설치**: `pip install tiktoken` 후 재시작
2. **특수 모델**: OpenAI 토크나이저 기반이므로 다른 모델은 근사치
3. **한국어/특수문자**: 일부 언어에서 오차 발생 가능

---

## Q: 스트리밍 vs 비스트리밍?

**A**:
- **스트리밍** (`--stream`): TTFT, TPOT, ITL 개별 측정 가능
- **비스트리밍** (`--no-stream`): E2E만 정확, TTFT = E2E

정확한 LLM 메트릭을 위해 **스트리밍 모드를 권장**합니다.

---

## Q: 동시성 레벨 선택 가이드?

**A**:
| 목적 | 권장 동시성 |
|------|------------|
| 기본선 측정 | 1 |
| 일반 사용 시뮬레이션 | 10-50 |
| 피크 부하 테스트 | 100+ |
| 한계 테스트 | 서버 용량까지 점진적 증가 |

여러 동시성 레벨로 테스트하여 성능 변화 곡선을 파악하세요.

---

## Q: Validation 기능이 작동하지 않는 경우?

**A**:
1. **Docker 접근 권한**: `docker logs` 명령어 실행 권한 필요
2. **컨테이너 이름 확인**: vLLM 컨테이너 이름이 정확한지 확인 (`docker ps`로 확인)
3. **vLLM 로그 포맷**: vLLM 0.4+ 버전의 로그 포맷 필요
4. **자동 감지 실패**: `container_name`을 명시적으로 지정

---

## Q: Validation이 FAILED로 표시되는 이유?

**A**:
1. **오차 범위 초과**: tolerance 값을 늘려보세요 (기본 5%)
2. **네트워크 지연**: 클라이언트-서버 간 네트워크 상태 확인
3. **로그 수집 타이밍**: 테스트 전후 로그 스냅샷 타이밍 이슈
4. **부분 요청 손실**: 일부 요청이 로깅되지 않은 경우
